{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnpzZdc01IvW"
   },
   "source": [
    "## Description\n",
    "This notebook generates the data for the shortest problem. We use m-by-m grid graphs and a vertex-weighted version of the shortest path problem, following Vastelica et al and Berthet et al. The data consists of:\n",
    "  - pairs (d,x) where d is a five dim contextual vector and x encodes the shortest path.\n",
    "  - W, a d-by-m^2 matrix which maps contexts to vertex weights.\n",
    "  - other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-bkspm8Q1KUA",
    "outputId": "23196911-6c0a-42f3-f4ed-0d6ff84ea335"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import sys\n",
    "\n",
    "sys.path.append('/content/drive/MyDrive/Projects/2022-SPO-with-DYS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptWhuIof1MC0",
    "outputId": "95c753f6-dc9d-4b3e-c448-cbedf3d4a957"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'drive/MyDrive/Projects/2022-SPO-with-DYS'\n",
      "/content/drive/MyDrive/Projects/2022-SPO-with-DYS\n"
     ]
    }
   ],
   "source": [
    "cd drive/MyDrive/Projects/2022-SPO-with-DYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "iGYw-_NI1Iva"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from GenerateShortestPathData import create_shortest_path_data\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ssvGZ8201Ivc"
   },
   "outputs": [],
   "source": [
    "## Fix some parameters\n",
    "train_size = 10\n",
    "test_size = 2\n",
    "context_size = 5\n",
    "# m_max = 25 # generate m-by-m graphs, with m in increments of 5, between 5 and m_max inclusive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZBr2WNgT1Ivc",
    "outputId": "35bbc070-b068-4b1f-88fd-0fd092622765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start building dataset for m = 100\n"
     ]
    }
   ],
   "source": [
    "# Loop over graph sizes\n",
    "# grid_array = [5,10,15,20,25,50,100]\n",
    "# for m in grid_array:\n",
    "m = 100\n",
    "start_time = time.time()\n",
    "print('Start building dataset for m = ' + str(m))\n",
    "train_dataset_v, test_dataset_v, train_dataset_e, test_dataset_e, WW, A, b, num_edges, Edge_list = create_shortest_path_data(m, train_size, test_size, context_size)\n",
    "end_time = time.time()\n",
    "print('Created data! Now saving')\n",
    "state = {\n",
    "      'WW': WW,\n",
    "      'train_dataset_v': train_dataset_v,\n",
    "      'test_dataset_v': test_dataset_v,\n",
    "      'train_dataset_e': train_dataset_e,\n",
    "      'test_dataset_e': test_dataset_e,\n",
    "      'm': m,\n",
    "      'A':A,\n",
    "      'b':b,\n",
    "      'num_edges': num_edges,\n",
    "      'Edge_list': Edge_list,\n",
    "      }\n",
    "save_dir = './shortest_path_data/'\n",
    "state_path = save_dir + 'Shortest_Path_training_data' + str(m) +'.pth'\n",
    "torch.save(state, state_path)\n",
    "print('Finished building dataset for m = ' + str(m), ', Time = ', end_time - start_time, ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_P_vred41Ive"
   },
   "source": [
    "## Examine some paths\n",
    "The next two blocks are test code to see if the new data generating functions are working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13vOhqn21Ive"
   },
   "outputs": [],
   "source": [
    "## Examine some paths\n",
    "state = torch.load('./shortest_path_data/Shortest_Path_training_data5.pth')\n",
    "\n",
    "## Extract data from state\n",
    "train_dataset_e = state['train_dataset_e']\n",
    "test_dataset_e = state['test_dataset_e']\n",
    "train_dataset_v = state['train_dataset_v']\n",
    "test_dataset_v = state['test_dataset_v']\n",
    "m = state[\"m\"]\n",
    "A = state[\"A\"].float()\n",
    "b = state[\"b\"].float()\n",
    "num_edges = state[\"num_edges\"]\n",
    "Edge_list = state[\"Edge_list\"]\n",
    "Edge_list_torch = torch.tensor(Edge_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUjJnKwh1Ivj"
   },
   "source": [
    "## Visualization\n",
    "The next few blocks help visualize the outputs. Just dumping them in this notebook temporarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "boPxUzcp1Ivk",
    "outputId": "eaf44886-ca1d-4201-f21f-d6f17fec9a23"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2d64394ce298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEdge_to_Node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0md_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0md_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpath_batch\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpath_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "from source.utils import Edge_to_Node\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loader_e = DataLoader(dataset=train_dataset_e, batch_size=200,\n",
    "                                  shuffle=False)\n",
    "d_batch, path_batch = next(iter(train_loader_e))\n",
    "\n",
    "train_loader_v = DataLoader(dataset=train_dataset_v, batch_size=200,\n",
    "                                  shuffle=False)\n",
    "d_batch_v, path_batch_v = next(iter(train_loader_v))\n",
    "\n",
    "for i in range(98,100):\n",
    "    # print(Edge_to_Node(path_batch[i], Edge_list, m,'cpu'))\n",
    "    plt.imshow(path_batch_v[i])\n",
    "    plt.show()\n",
    "#     plt.imshow(Edge_to_Node(path_batch[i], Edge_list, m,'cpu') - path_batch_v[i])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "av0bE0Y41Ivl"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "d_batch, path_batch = next(iter(test_loader))\n",
    "\n",
    "d_batch = d_batch.to(device)\n",
    "path_batch =path_batch.to(device)\n",
    "path_pred = net(d_batch)\n",
    "\n",
    "for i in range(10):\n",
    "  node_map = Edge_to_Node(path_batch[i], Edge_list, m,'cuda:0')\n",
    "  plt.matshow(node_map.to('cpu'))\n",
    "  # plt.savefig('10_by_10_True_path'+str(i)+'.pdf')\n",
    "  plt.show()\n",
    "  node_map_pred = Edge_to_Node(path_pred[i], Edge_list, m,'cuda:0')\n",
    "  plt.matshow(node_map_pred.to('cpu'))\n",
    "  plt.savefig('10_by_10_Pred_path'+str(i)+'.pdf')\n",
    "  # print(path_pred[i])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
