{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing path length as an accuracy measure\n",
    "\n",
    "Quick notebook to test the validity of this idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./source/') # append files from source folder\n",
    "\n",
    "import torch\n",
    "from GenerateShortestPathData import create_shortest_path_data\n",
    "from ModelsShortestPath import ShortestPathNet, Cvx_ShortestPathNet, Pert_ShortestPathNet, BB_ShortestPathNet\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import Regret\n",
    "import time as time\n",
    "from Trainer import trainer\n",
    "import numpy as np\n",
    "\n",
    "## Set device\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some fixed hyperparameters\n",
    "max_epochs = 100\n",
    "init_lr = 1e-2 # initial learning rate. We're using a scheduler.\n",
    "torch.manual_seed(0)\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some arrays\n",
    "tl_trained_DYS = [] # test loss\n",
    "tt_trained_DYS = [] # training time\n",
    "ta_trained_DYS = [] # test accuracy of trained model\n",
    "ne_trained_DYS = [] # number of epochs completed during training\n",
    "\n",
    "tl_trained_CVX = []\n",
    "tt_trained_CVX = []\n",
    "ta_trained_CVX = []\n",
    "ne_trained_CVX = []\n",
    "\n",
    "tl_trained_PertOpt = []\n",
    "tt_trained_PertOpt = []\n",
    "ta_trained_PertOpt = []\n",
    "ne_trained_PertOpt = []\n",
    "\n",
    "tl_trained_BB = []\n",
    "tt_trained_BB = []\n",
    "ta_trained_BB = []\n",
    "ne_trained_BB = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------- TRAINING CVX GRID 5-by-5 --------------------------------------------\n",
      "epoch:  0 | ave_tr_loss:  3.40e-02 | te_loss:  1.31e-01 | acc.:  0.030000 | lr:  1.00e-02 | regret:  20.440731 | time:  4.952297       \n",
      "epoch:  1 | ave_tr_loss:  5.41e-02 | te_loss:  1.18e-01 | acc.:  0.025000 | lr:  1.00e-02 | regret:  36.355408 | time:  12.668065      \n",
      "epoch:  2 | ave_tr_loss:  6.77e-02 | te_loss:  1.11e-01 | acc.:  0.000000 | lr:  1.00e-02 | regret:  18.604237 | time:  19.699751      \n",
      "epoch:  3 | ave_tr_loss:  7.69e-02 | te_loss:  1.06e-01 | acc.:  0.020000 | lr:  1.00e-02 | regret:  14.182945 | time:  26.625497      \n",
      "epoch:  4 | ave_tr_loss:  8.30e-02 | te_loss:  1.00e-01 | acc.:  0.110000 | lr:  1.00e-02 | regret:  15.789086 | time:  33.544328      \n",
      "epoch:  5 | ave_tr_loss:  8.61e-02 | te_loss:  9.50e-02 | acc.:  0.155000 | lr:  1.00e-02 | regret:  11.954643 | time:  40.443361      \n",
      "epoch:  6 | ave_tr_loss:  8.71e-02 | te_loss:  8.79e-02 | acc.:  0.215000 | lr:  1.00e-02 | regret:  8.800279 | time:  47.328528      \n",
      "epoch:  7 | ave_tr_loss:  8.65e-02 | te_loss:  8.17e-02 | acc.:  0.245000 | lr:  1.00e-02 | regret:  7.683050 | time:  54.364955      \n",
      "epoch:  8 | ave_tr_loss:  8.45e-02 | te_loss:  7.01e-02 | acc.:  0.370000 | lr:  1.00e-02 | regret:  6.170884 | time:  61.272988      \n",
      "epoch:  9 | ave_tr_loss:  8.00e-02 | te_loss:  5.59e-02 | acc.:  0.695000 | lr:  1.00e-02 | regret:  1.039117 | time:  68.321994      \n",
      "epoch:  10 | ave_tr_loss:  7.52e-02 | te_loss:  5.02e-02 | acc.:  0.730000 | lr:  1.00e-02 | regret:  0.866021 | time:  75.236392      \n",
      "epoch:  11 | ave_tr_loss:  7.03e-02 | te_loss:  4.78e-02 | acc.:  0.725000 | lr:  1.00e-02 | regret:  1.013413 | time:  82.141121      \n",
      "epoch:  12 | ave_tr_loss:  6.57e-02 | te_loss:  4.33e-02 | acc.:  0.750000 | lr:  1.00e-02 | regret:  0.943006 | time:  89.073524      \n",
      "epoch:  13 | ave_tr_loss:  6.12e-02 | te_loss:  3.94e-02 | acc.:  0.745000 | lr:  1.00e-02 | regret:  0.868914 | time:  95.974335      \n",
      "epoch:  14 | ave_tr_loss:  5.71e-02 | te_loss:  3.78e-02 | acc.:  0.790000 | lr:  1.00e-02 | regret:  0.710669 | time:  102.903771     \n",
      "epoch:  15 | ave_tr_loss:  5.32e-02 | te_loss:  3.55e-02 | acc.:  0.795000 | lr:  1.00e-02 | regret:  1.069079 | time:  109.796161     \n",
      "epoch:  16 | ave_tr_loss:  4.98e-02 | te_loss:  3.35e-02 | acc.:  0.805000 | lr:  1.00e-02 | regret:  0.861755 | time:  116.702064     \n",
      "epoch:  17 | ave_tr_loss:  4.67e-02 | te_loss:  3.19e-02 | acc.:  0.825000 | lr:  1.00e-02 | regret:  0.848172 | time:  123.567485     \n",
      "epoch:  18 | ave_tr_loss:  4.40e-02 | te_loss:  3.05e-02 | acc.:  0.820000 | lr:  1.00e-02 | regret:  0.837566 | time:  130.466542     \n",
      "epoch:  19 | ave_tr_loss:  4.15e-02 | te_loss:  2.89e-02 | acc.:  0.845000 | lr:  1.00e-02 | regret:  0.628454 | time:  137.304730     \n",
      "epoch:  20 | ave_tr_loss:  3.93e-02 | te_loss:  2.84e-02 | acc.:  0.850000 | lr:  1.00e-02 | regret:  0.807304 | time:  144.186174     \n",
      "epoch:  21 | ave_tr_loss:  3.73e-02 | te_loss:  2.69e-02 | acc.:  0.855000 | lr:  1.00e-02 | regret:  0.600737 | time:  150.989987     \n",
      "epoch:  22 | ave_tr_loss:  3.56e-02 | te_loss:  2.61e-02 | acc.:  0.855000 | lr:  1.00e-02 | regret:  0.450448 | time:  157.849366     \n",
      "epoch:  23 | ave_tr_loss:  3.40e-02 | te_loss:  2.56e-02 | acc.:  0.865000 | lr:  1.00e-02 | regret:  0.555464 | time:  164.669344     \n",
      "epoch:  24 | ave_tr_loss:  3.26e-02 | te_loss:  2.48e-02 | acc.:  0.865000 | lr:  1.00e-02 | regret:  0.715615 | time:  171.512539     \n",
      "epoch:  25 | ave_tr_loss:  3.14e-02 | te_loss:  2.39e-02 | acc.:  0.860000 | lr:  1.00e-02 | regret:  0.608346 | time:  178.515496     \n",
      "epoch:  26 | ave_tr_loss:  3.03e-02 | te_loss:  2.37e-02 | acc.:  0.870000 | lr:  1.00e-02 | regret:  0.701284 | time:  185.503370     \n",
      "epoch:  27 | ave_tr_loss:  2.92e-02 | te_loss:  2.30e-02 | acc.:  0.865000 | lr:  1.00e-02 | regret:  0.601853 | time:  192.484945     \n",
      "epoch:  28 | ave_tr_loss:  2.84e-02 | te_loss:  2.22e-02 | acc.:  0.885000 | lr:  1.00e-02 | regret:  0.355308 | time:  199.590734     \n",
      "epoch:  29 | ave_tr_loss:  2.75e-02 | te_loss:  2.22e-02 | acc.:  0.870000 | lr:  1.00e-02 | regret:  0.442349 | time:  206.547258     \n",
      "epoch:  30 | ave_tr_loss:  2.68e-02 | te_loss:  2.11e-02 | acc.:  0.900000 | lr:  1.00e-02 | regret:  0.075273 | time:  213.508397     \n",
      "epoch:  31 | ave_tr_loss:  2.61e-02 | te_loss:  2.09e-02 | acc.:  0.890000 | lr:  1.00e-02 | regret:  0.235674 | time:  220.242665     \n",
      "epoch:  32 | ave_tr_loss:  2.55e-02 | te_loss:  2.06e-02 | acc.:  0.895000 | lr:  1.00e-02 | regret:  0.473069 | time:  227.015531     \n",
      "epoch:  33 | ave_tr_loss:  2.51e-02 | te_loss:  1.98e-02 | acc.:  0.910000 | lr:  1.00e-02 | regret:  0.192491 | time:  233.929519     \n",
      "epoch:  34 | ave_tr_loss:  2.46e-02 | te_loss:  2.06e-02 | acc.:  0.885000 | lr:  1.00e-02 | regret:  0.275659 | time:  240.913853     \n",
      "epoch:  35 | ave_tr_loss:  2.42e-02 | te_loss:  1.89e-02 | acc.:  0.910000 | lr:  1.00e-02 | regret:  0.038364 | time:  247.612353     \n",
      "epoch:  36 | ave_tr_loss:  2.37e-02 | te_loss:  1.99e-02 | acc.:  0.900000 | lr:  1.00e-02 | regret:  0.181965 | time:  254.337707     \n",
      "epoch:  37 | ave_tr_loss:  2.32e-02 | te_loss:  1.85e-02 | acc.:  0.910000 | lr:  1.00e-02 | regret:  0.069984 | time:  261.029875     \n",
      "epoch:  38 | ave_tr_loss:  2.28e-02 | te_loss:  1.91e-02 | acc.:  0.910000 | lr:  1.00e-02 | regret:  0.176504 | time:  267.786134     \n",
      "epoch:  39 | ave_tr_loss:  2.23e-02 | te_loss:  1.84e-02 | acc.:  0.915000 | lr:  1.00e-02 | regret:  0.187596 | time:  274.466711     \n",
      "epoch:  40 | ave_tr_loss:  2.19e-02 | te_loss:  1.79e-02 | acc.:  0.910000 | lr:  1.00e-02 | regret:  0.188082 | time:  281.391844     \n",
      "epoch:  41 | ave_tr_loss:  2.16e-02 | te_loss:  1.80e-02 | acc.:  0.910000 | lr:  1.00e-02 | regret:  0.038592 | time:  288.247041     \n",
      "epoch:  42 | ave_tr_loss:  2.13e-02 | te_loss:  1.80e-02 | acc.:  0.925000 | lr:  1.00e-02 | regret:  0.181298 | time:  294.971211     \n",
      "epoch:  43 | ave_tr_loss:  2.09e-02 | te_loss:  1.73e-02 | acc.:  0.925000 | lr:  1.00e-02 | regret:  0.025787 | time:  301.794959     \n",
      "epoch:  44 | ave_tr_loss:  2.06e-02 | te_loss:  1.75e-02 | acc.:  0.910000 | lr:  1.00e-02 | regret:  0.188082 | time:  308.478343     \n",
      "epoch:  45 | ave_tr_loss:  2.04e-02 | te_loss:  1.73e-02 | acc.:  0.935000 | lr:  1.00e-02 | regret:  0.024414 | time:  315.281279     \n",
      "epoch:  46 | ave_tr_loss:  2.01e-02 | te_loss:  1.67e-02 | acc.:  0.910000 | lr:  1.00e-02 | regret:  0.033954 | time:  322.061645     \n",
      "epoch:  47 | ave_tr_loss:  1.98e-02 | te_loss:  1.71e-02 | acc.:  0.935000 | lr:  1.00e-02 | regret:  0.024414 | time:  328.778895     \n",
      "epoch:  48 | ave_tr_loss:  1.97e-02 | te_loss:  1.68e-02 | acc.:  0.935000 | lr:  1.00e-02 | regret:  0.024414 | time:  335.464036     \n",
      "epoch:  49 | ave_tr_loss:  1.95e-02 | te_loss:  1.61e-02 | acc.:  0.915000 | lr:  1.00e-02 | regret:  0.033468 | time:  342.089528     \n",
      "epoch:  50 | ave_tr_loss:  1.93e-02 | te_loss:  1.69e-02 | acc.:  0.930000 | lr:  1.00e-02 | regret:  0.170538 | time:  348.741024     \n",
      "epoch:  51 | ave_tr_loss:  1.91e-02 | te_loss:  1.61e-02 | acc.:  0.915000 | lr:  1.00e-02 | regret:  0.187596 | time:  355.345511     \n",
      "epoch:  52 | ave_tr_loss:  1.89e-02 | te_loss:  1.63e-02 | acc.:  0.925000 | lr:  1.00e-02 | regret:  0.026475 | time:  362.164782     \n",
      "epoch:  53 | ave_tr_loss:  1.87e-02 | te_loss:  1.60e-02 | acc.:  0.940000 | lr:  1.00e-02 | regret:  0.024304 | time:  368.765585     \n",
      "epoch:  54 | ave_tr_loss:  1.85e-02 | te_loss:  1.60e-02 | acc.:  0.925000 | lr:  1.00e-02 | regret:  0.029251 | time:  375.378220     \n",
      "epoch:  55 | ave_tr_loss:  1.83e-02 | te_loss:  1.55e-02 | acc.:  0.920000 | lr:  1.00e-02 | regret:  0.184484 | time:  381.940410     \n",
      "epoch:  56 | ave_tr_loss:  1.82e-02 | te_loss:  1.57e-02 | acc.:  0.940000 | lr:  1.00e-02 | regret:  0.024304 | time:  388.734115     \n",
      "epoch:  57 | ave_tr_loss:  1.79e-02 | te_loss:  1.54e-02 | acc.:  0.935000 | lr:  1.00e-02 | regret:  0.024414 | time:  395.325160     \n",
      "epoch:  58 | ave_tr_loss:  1.78e-02 | te_loss:  1.49e-02 | acc.:  0.940000 | lr:  1.00e-02 | regret:  0.020059 | time:  401.962890     \n",
      "epoch:  59 | ave_tr_loss:  1.77e-02 | te_loss:  1.55e-02 | acc.:  0.940000 | lr:  1.00e-02 | regret:  0.024304 | time:  408.564625     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  60 | ave_tr_loss:  1.75e-02 | te_loss:  1.47e-02 | acc.:  0.930000 | lr:  1.00e-02 | regret:  0.025519 | time:  415.233785     \n",
      "epoch:  61 | ave_tr_loss:  1.73e-02 | te_loss:  1.50e-02 | acc.:  0.935000 | lr:  1.00e-02 | regret:  0.024414 | time:  421.817001     \n",
      "epoch:  62 | ave_tr_loss:  1.72e-02 | te_loss:  1.51e-02 | acc.:  0.935000 | lr:  1.00e-02 | regret:  0.024414 | time:  428.425050     \n",
      "epoch:  63 | ave_tr_loss:  1.71e-02 | te_loss:  1.45e-02 | acc.:  0.940000 | lr:  1.00e-02 | regret:  0.019439 | time:  435.057603     \n",
      "epoch:  64 | ave_tr_loss:  1.69e-02 | te_loss:  1.47e-02 | acc.:  0.935000 | lr:  1.00e-02 | regret:  0.024414 | time:  441.654427     \n",
      "epoch:  65 | ave_tr_loss:  1.68e-02 | te_loss:  1.47e-02 | acc.:  0.940000 | lr:  1.00e-02 | regret:  0.024304 | time:  448.233211     \n",
      "epoch:  66 | ave_tr_loss:  1.67e-02 | te_loss:  1.42e-02 | acc.:  0.935000 | lr:  1.00e-02 | regret:  0.020545 | time:  454.873141     \n",
      "epoch:  67 | ave_tr_loss:  1.66e-02 | te_loss:  1.46e-02 | acc.:  0.940000 | lr:  1.00e-02 | regret:  0.021626 | time:  461.471362     \n",
      "epoch:  68 | ave_tr_loss:  1.65e-02 | te_loss:  1.40e-02 | acc.:  0.930000 | lr:  1.00e-02 | regret:  0.025519 | time:  468.118150     \n",
      "epoch:  69 | ave_tr_loss:  1.65e-02 | te_loss:  1.38e-02 | acc.:  0.945000 | lr:  1.00e-02 | regret:  0.017455 | time:  474.741316     \n",
      "epoch:  70 | ave_tr_loss:  1.65e-02 | te_loss:  1.45e-02 | acc.:  0.945000 | lr:  1.00e-02 | regret:  0.016652 | time:  481.412831     \n",
      "epoch:  71 | ave_tr_loss:  1.64e-02 | te_loss:  1.36e-02 | acc.:  0.940000 | lr:  1.00e-02 | regret:  0.017564 | time:  488.023428     \n",
      "epoch:  72 | ave_tr_loss:  1.64e-02 | te_loss:  1.44e-02 | acc.:  0.940000 | lr:  1.00e-02 | regret:  0.022776 | time:  494.678231     \n",
      "epoch:  73 | ave_tr_loss:  1.62e-02 | te_loss:  1.35e-02 | acc.:  0.950000 | lr:  1.00e-02 | regret:  0.015973 | time:  501.284677     \n",
      "epoch:  74 | ave_tr_loss:  1.61e-02 | te_loss:  1.43e-02 | acc.:  0.940000 | lr:  1.00e-02 | regret:  0.022776 | time:  508.009831     \n",
      "epoch:  75 | ave_tr_loss:  1.60e-02 | te_loss:  1.31e-02 | acc.:  0.940000 | lr:  1.00e-02 | regret:  0.017564 | time:  514.601245     \n",
      "epoch:  76 | ave_tr_loss:  1.58e-02 | te_loss:  1.40e-02 | acc.:  0.950000 | lr:  1.00e-02 | regret:  0.016542 | time:  521.295354     \n",
      "epoch:  77 | ave_tr_loss:  1.57e-02 | te_loss:  1.35e-02 | acc.:  0.945000 | lr:  1.00e-02 | regret:  0.016459 | time:  527.953030     \n",
      "epoch:  78 | ave_tr_loss:  1.56e-02 | te_loss:  1.33e-02 | acc.:  0.945000 | lr:  1.00e-02 | regret:  0.016459 | time:  534.658557     \n",
      "epoch:  79 | ave_tr_loss:  1.55e-02 | te_loss:  1.33e-02 | acc.:  0.950000 | lr:  1.00e-02 | regret:  0.016349 | time:  541.297985     \n",
      "epoch:  80 | ave_tr_loss:  1.55e-02 | te_loss:  1.32e-02 | acc.:  0.955000 | lr:  1.00e-02 | regret:  0.013562 | time:  547.947261     \n",
      "epoch:  81 | ave_tr_loss:  1.54e-02 | te_loss:  1.37e-02 | acc.:  0.935000 | lr:  1.00e-02 | regret:  0.022693 | time:  554.549440     \n",
      "epoch:  82 | ave_tr_loss:  1.54e-02 | te_loss:  1.27e-02 | acc.:  0.945000 | lr:  1.00e-02 | regret:  0.017078 | time:  561.169704     \n",
      "epoch:  83 | ave_tr_loss:  1.53e-02 | te_loss:  1.42e-02 | acc.:  0.935000 | lr:  1.00e-02 | regret:  0.168195 | time:  567.763447     \n",
      "epoch:  84 | ave_tr_loss:  1.51e-02 | te_loss:  1.25e-02 | acc.:  0.945000 | lr:  1.00e-02 | regret:  0.017078 | time:  574.435926     \n",
      "epoch:  85 | ave_tr_loss:  1.52e-02 | te_loss:  1.32e-02 | acc.:  0.950000 | lr:  1.00e-02 | regret:  0.013672 | time:  581.071466     \n",
      "epoch:  86 | ave_tr_loss:  1.52e-02 | te_loss:  1.33e-02 | acc.:  0.950000 | lr:  1.00e-02 | regret:  0.013672 | time:  587.673964     \n",
      "epoch:  87 | ave_tr_loss:  1.51e-02 | te_loss:  1.24e-02 | acc.:  0.945000 | lr:  1.00e-02 | regret:  0.017078 | time:  594.245290     \n",
      "epoch:  88 | ave_tr_loss:  1.51e-02 | te_loss:  1.34e-02 | acc.:  0.935000 | lr:  1.00e-02 | regret:  0.020037 | time:  600.854709     \n",
      "epoch:  89 | ave_tr_loss:  1.50e-02 | te_loss:  1.25e-02 | acc.:  0.945000 | lr:  1.00e-02 | regret:  0.017078 | time:  607.458301     \n",
      "epoch:  90 | ave_tr_loss:  1.49e-02 | te_loss:  1.33e-02 | acc.:  0.950000 | lr:  1.00e-02 | regret:  0.016542 | time:  614.093651     \n",
      "epoch:  91 | ave_tr_loss:  1.48e-02 | te_loss:  1.23e-02 | acc.:  0.940000 | lr:  1.00e-02 | regret:  0.017564 | time:  620.701717     \n",
      "epoch:  92 | ave_tr_loss:  1.47e-02 | te_loss:  1.27e-02 | acc.:  0.950000 | lr:  1.00e-02 | regret:  0.013672 | time:  627.393289     \n",
      "epoch:  93 | ave_tr_loss:  1.47e-02 | te_loss:  1.26e-02 | acc.:  0.950000 | lr:  1.00e-02 | regret:  0.013672 | time:  634.043992     \n"
     ]
    }
   ],
   "source": [
    "for grid_size in range(5, 6, 5):\n",
    "    \n",
    "    ## Load data\n",
    "    data_path = './shortest_path_data/Shortest_Path_training_data'+str(grid_size)+'.pth'\n",
    "    state = torch.load(data_path)\n",
    "\n",
    "    ## Extract data from state\n",
    "    train_dataset_e = state['train_dataset_e']\n",
    "    test_dataset_e = state['test_dataset_e']\n",
    "    train_dataset_v = state['train_dataset_v']\n",
    "    test_dataset_v = state['test_dataset_v']\n",
    "    m = state[\"m\"]\n",
    "    A = state[\"A\"].float()\n",
    "    WW = state[\"WW\"].float()\n",
    "    b = state[\"b\"].float()\n",
    "    num_edges = state[\"num_edges\"]\n",
    "    Edge_list = state[\"Edge_list\"]\n",
    "    Edge_list_torch = torch.tensor(Edge_list)\n",
    "    \n",
    "    ## Set device\n",
    "    device = 'cuda:0'\n",
    "    \n",
    "#     ## Load model/network\n",
    "#     DYS_net = ShortestPathNet(A, b, num_vertices = grid_size**2, num_edges = num_edges ,\n",
    "#                       Edges = Edge_list_torch.to(device), context_size = 5)\n",
    "#     DYS_net.to(device)\n",
    "    \n",
    "#     # Train\n",
    "#     tl_DYS, tt_DYS, ta_DYS = trainer(DYS_net, train_dataset_e, test_dataset_e, grid_size, WW, \n",
    "#                                     max_epochs, init_lr, graph_type='E', Edge_list = Edge_list)\n",
    "    \n",
    "    ## Load model/network\n",
    "    CVX_net = Cvx_ShortestPathNet(A.float(), b.float(), 5)\n",
    "    CVX_net.to(device)\n",
    "\n",
    "    # Train\n",
    "    print('\\n-------------------------------------------- TRAINING CVX GRID ' + str(grid_size) + '-by-' + str(grid_size) + ' --------------------------------------------')\n",
    "    start_time = time.time()\n",
    "    tl_CVX, tt_CVX, ta_CVX = trainer(CVX_net, train_dataset_e, test_dataset_e, grid_size, WW,\n",
    "                            max_epochs, init_lr, graph_type='E', Edge_list = Edge_list, max_time=np.inf)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print('\\n time to train CVX GRID ' + str(grid_size) + '-by-' + str(grid_size), ' = ', end_time-start_time, ' seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = 'cuda:0'\n",
    "WW = state[\"WW\"].float()\n",
    "WW = WW.to(device)\n",
    "test_loader_e = DataLoader(dataset=test_dataset_e, batch_size=200, shuffle=False)\n",
    "d_batch, path_batch = next(iter(test_loader_e))\n",
    "d_batch = d_batch.to(device)\n",
    "path_batch = path_batch.to(device)\n",
    "pred_batch = DYS_net(d_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1702, 7.9031, 6.9456, 6.7948, 5.0239],\n",
      "        [9.5281, 4.9118, 1.9294, 6.3261, 3.4219],\n",
      "        [5.9928, 5.4186, 8.9691, 7.9130, 0.6349],\n",
      "        [4.9403, 0.5317, 3.8679, 3.4464, 5.3368],\n",
      "        [7.3080, 0.6198, 9.4260, 2.6691, 7.4828],\n",
      "        [8.5245, 1.7376, 2.8182, 9.9599, 9.4462],\n",
      "        [5.7449, 7.1972, 3.8598, 4.2761, 5.9908],\n",
      "        [9.2536, 8.7777, 7.4495, 2.7658, 7.4805],\n",
      "        [7.9753, 2.1293, 7.7938, 1.0720, 5.6085],\n",
      "        [7.8435, 1.6007, 4.8955, 5.8478, 2.7619],\n",
      "        [9.6259, 5.0974, 6.6603, 5.6137, 5.5263],\n",
      "        [9.3561, 5.9173, 7.5534, 9.1608, 3.7813],\n",
      "        [2.0364, 7.6369, 9.5852, 0.7631, 0.6770],\n",
      "        [1.2583, 8.0441, 7.9009, 7.7743, 6.7167],\n",
      "        [8.3019, 8.8591, 6.9718, 2.9538, 6.3357],\n",
      "        [8.7479, 9.4746, 8.7119, 1.7498, 0.2157],\n",
      "        [6.7123, 3.9661, 0.1506, 5.4374, 7.2124],\n",
      "        [0.6349, 7.7523, 8.8939, 3.3827, 4.6236],\n",
      "        [2.6295, 6.6660, 2.7649, 7.7292, 8.8474],\n",
      "        [2.5740, 7.9612, 2.0259, 7.9373, 2.5515],\n",
      "        [0.1928, 7.4078, 3.8105, 4.1470, 6.1128],\n",
      "        [0.5020, 6.1577, 4.3453, 8.5690, 5.3348],\n",
      "        [0.9707, 8.5812, 0.0681, 7.0939, 5.5648],\n",
      "        [3.3742, 2.4773, 8.5235, 6.3664, 2.4003],\n",
      "        [9.7178, 0.6819, 5.0147, 3.4806, 7.9853]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(WW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Regret() missing 4 required positional arguments: 'type', 'Edge_list', 'grid_size', and 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1bcbec403435>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Regret() missing 4 required positional arguments: 'type', 'Edge_list', 'grid_size', and 'device'"
     ]
    }
   ],
   "source": [
    "regret = Regret(WW,d_batch, path_batch, pred_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
